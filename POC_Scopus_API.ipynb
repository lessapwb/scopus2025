{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega vari√°veis de ambiente do arquivo .env\n",
    "load_dotenv()\n",
    "scopus_api = os.getenv(\"scopus_api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P√°gina sem novos resultados. Encerrando a busca.\n",
      "Total de resultados: 144\n"
     ]
    }
   ],
   "source": [
    "# Definindo a URL da API\n",
    "url = \"https://api.elsevier.com/content/search/scopus\"\n",
    "\n",
    "# Par√¢metros para a requisi√ß√£o\n",
    "params = {\n",
    "    \"query\": '(TITLE ( \"market* segmentation\" AND \"data-driven\" ) OR KEY ( \"marketing\" AND \"data-driven\" )) AND DOCTYPE(ar)',\n",
    "    \"apiKey\": scopus_api,\n",
    "    \"count\": 200,  # Definindo o n√∫mero m√°ximo de registros por p√°gina\n",
    "    \"start\": 0  # Come√ßando a partir do primeiro registro\n",
    "}\n",
    "\n",
    "all_results = []  # Lista para armazenar todos os resultados\n",
    "\n",
    "while True:\n",
    "    # Fazendo a requisi√ß√£o GET\n",
    "    response = requests.get(url=url, params=params)\n",
    "\n",
    "    # Verificando se a requisi√ß√£o foi bem sucedida\n",
    "    if response.status_code == 200:\n",
    "        # Transformando a resposta em um objeto JSON\n",
    "        data = response.json()\n",
    "\n",
    "        # Verificando se a chave 'search-results' est√° presente na resposta\n",
    "        entries = data['search-results'].get('entry')\n",
    "\n",
    "        if entries:\n",
    "            all_results.extend(entries)\n",
    "        else:\n",
    "            print(\"P√°gina sem novos resultados. Encerrando a busca.\")\n",
    "            break\n",
    "\n",
    "        # Verificando se h√° mais resultados para recuperar\n",
    "        if int(data['search-results']['opensearch:itemsPerPage']) == 0:\n",
    "            # Se n√£o houver mais resultados, interrompa o loop\n",
    "            break\n",
    "\n",
    "        # Atualizando o √≠ndice do pr√≥ximo registro a ser recuperado\n",
    "        params['start'] += params['count']\n",
    "    else:\n",
    "        # Tenta capturar a mensagem de erro detalhada\n",
    "        try:\n",
    "            error_json = response.json()\n",
    "            error_info = error_json.get(\"service-error\", {}).get(\"status\", {})\n",
    "            status_code = error_info.get(\"statusCode\", \"Desconhecido\")\n",
    "            status_text = error_info.get(\"statusText\", \"Sem mensagem\")\n",
    "\n",
    "            print(f\"Erro da API: {status_code} - {status_text}\")\n",
    "        except Exception as e:\n",
    "            print(\"Erro inesperado:\", e)\n",
    "\n",
    "        break\n",
    "\n",
    "# Imprimindo o n√∫mero total de resultados obtidos\n",
    "print(\"Total de resultados:\", len(all_results))\n",
    "\n",
    "df_results = pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo colunas desnecess√°rias\n",
    "columns = ['@_fa', \n",
    "           'link',\n",
    "           'prism:url',\n",
    "           'eid',\n",
    "           'pii',\n",
    "           'subtype',\n",
    "           'source-id',\n",
    "           'openaccess',\n",
    "           'openaccessFlag',\n",
    "           'article-number',\n",
    "           'freetoread',\n",
    "           'freetoreadLabel',\n",
    "           'prism:aggregationType',\n",
    "           'prism:issn',\n",
    "           'prism:volume',\n",
    "           'prism:issueIdentifier',\n",
    "           'prism:pageRange',\n",
    "           'prism:coverDisplayDate',\n",
    "           'prism:isbn',\n",
    "           'prism:eIssn',\n",
    "           'pubmed-id']\n",
    "\n",
    "\n",
    "df_results = df_results.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando a coluna dc:identifier - Removendo o prefixo 'SCOPUS_ID:'\n",
    "df_results['dc:identifier'] = df_results['dc:identifier'].str.replace('SCOPUS_ID:', '')\n",
    "\n",
    "# Tratando a coluna affiliation - Transformando em uma lista de strings\n",
    "# Removendo [] da coluna affiliation\n",
    "df_results['affiliation'] = df_results['affiliation'].apply(lambda x: [aff['affilname'] for aff in x][0] if isinstance(x, list) and x else None)\n",
    "\n",
    "# Filtrando para registros que s√£o artigos\n",
    "df_results = df_results[df_results['subtypeDescription'] == 'Article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a coluna 'abstract' ao DataFrame\n",
    "\n",
    "# Fun√ß√£o para obter o resumo com base no DOI\n",
    "def get_abstract(doi):\n",
    "    url = f\"https://api.elsevier.com/content/abstract/doi/{doi}?apiKey={scopus_api}\"\n",
    "    headers = {'Accept': 'application/json'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    try:\n",
    "        abstract_content = data[\"abstracts-retrieval-response\"][\"item\"][\"bibrecord\"][\"head\"][\"abstracts\"]\n",
    "        return abstract_content\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "# Itera sobre os valores da coluna prism:doi e obt√©m os resumos\n",
    "df_results['abstract'] = df_results['prism:doi'].apply(get_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando dataframe como csv\n",
    "df_results.to_csv('base_scopus_ddm.csv', index=False)\n",
    "df_results.to_excel('base_scopus_ddm.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando llm para analisar a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Instale os pacotes antes (uma vez):\n",
    "# pip install pandas openai python-dotenv tiktoken\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega vari√°veis do .env\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Carrega a base filtrada\n",
    "df = pd.read_csv(\"base_scopus_ddm.csv\", usecols=[\n",
    "    \"dc:title\", \"dc:creator\", \"prism:publicationName\", \"prism:coverDate\",\n",
    "    \"prism:doi\", \"citedby-count\", \"affiliation\", \"subtypeDescription\", \"abstract\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Gera uma vers√£o estruturada de cada registro\n",
    "df[\"resumo_estruturado\"] = df.apply(lambda row: f\"\"\"\n",
    "T√≠tulo: {row['dc:title']}\n",
    "Autores: {row['dc:creator']}\n",
    "Peri√≥dico: {row['prism:publicationName']}\n",
    "Data: {row['prism:coverDate']}\n",
    "DOI: {row['prism:doi']}\n",
    "Cita√ß√µes: {row['citedby-count']}\n",
    "Afili√ß√£o: {row['affiliation']}\n",
    "Tipo: {row['subtypeDescription']}\n",
    "Resumo: {row['abstract']}\n",
    "\"\"\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Limita para os primeiros 200 artigos (ajust√°vel)\n",
    "texto_completo = \"\\n\\n\".join(df[\"resumo_estruturado\"].head(200).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Hist√≥rico do chat\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"Voc√™ √© um analista de dados bibliom√©tricos. Use somente a base fornecida para responder.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Aqui est√° a base: \\n\\n{texto_completo}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IA: A seguir alguns dos estudos da base que exploram algor√≠tmos de clustering ‚Äúavan√ßados‚Äù em segmenta√ß√£o de mercado, indo al√©m do simples K-Means:\n",
      "\n",
      "1) Budaya I.G.B.A. (2025)  \n",
      "   ‚ÄúApplication of Formal Concept Analysis and Clustering Algorithms to Analyze Customer Segments‚Äù  \n",
      "   Jurnal Resti, DOI:10.29207/resti.v9i2.6184  \n",
      "   ‚Ä¢ Usa K-Means e GMM para definir clusters em dados RFM.  \n",
      "   ‚Ä¢ Em seguida aplica Formal Concept Analysis (FCA) para categorizar as combina√ß√µes dos atributos (High/Low R, F, M), enriquecendo a interpreta√ß√£o dos segmentos.\n",
      "\n",
      "2) Uddin M.A. (2024)  \n",
      "   ‚ÄúData-driven strategies for digital native market segmentation using clustering‚Äù  \n",
      "   International Journal of Cognitive Computing in Engineering, DOI:10.1016/j.ijcce.2024.04.002  \n",
      "   ‚Ä¢ Compara K-Means, MiniBatch K-Means, AGNES (clustering hier√°rquico) e Fuzzy C-Means.  \n",
      "   ‚Ä¢ Avalia via √≠ndices de silhueta a capacidade de cada t√©cnica em agrupar interesses similares de consumidores digitais (adolescentes).\n",
      "\n",
      "3) Chen J.H. (2021)  \n",
      "   ‚ÄúSwarm-inspired data-driven approach for housing market segmentation: a case study of Taipei city‚Äù  \n",
      "   Journal of Housing and the Built Environment, DOI:10.1007/s10901-021-09824-1  \n",
      "   ‚Ä¢ Prop√µe um algoritmo inspirado em enxames (‚Äúswarm-inspired projection‚Äù) para projetar e segmentar mercados habitacionais de alta dimensionalidade.  \n",
      "   ‚Ä¢ Demonstra superioridade em obter segmentos estatisticamente bem explicados (modelos hed√¥nicos).\n",
      "\n",
      "4) Wu C. (2018)  \n",
      "   ‚ÄúModified data-driven framework for housing market segmentation‚Äù  \n",
      "   Journal of Urban Planning and Development, DOI:10.1061/(ASCE)UP.1943-5444.0000473  \n",
      "   ‚Ä¢ Substitui PCA por GWPCA (accounting for spatial heterogeneities) e utiliza DBSCAN (Density-Based Spatial Clustering) para delimitar submercados.  \n",
      "   ‚Ä¢ Valida a nova estrutura com an√°lises hed√¥nicas, mostrando ganhos em estabilidade e explica√ß√£o.\n",
      "\n",
      "Cada um desses artigos demonstra como t√©cnicas de clustering mais sofisticadas (GMM, Fuzzy C-Means, AGNES, DBSCAN, m√©todos inspirados em enxames etc.), muitas vezes combinadas com redu√ß√£o de dimensionalidade (PCA, GWPCA), podem revelar segmentos mais coesos e acion√°veis em variadas aplica√ß√µes de mercado.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Loop de conversa com base Scopus\n",
    "while True:\n",
    "    user_input = input(\"\\nVoc√™: \")\n",
    "    if user_input.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o4-mini-2025-04-16\",\n",
    "        messages=history\n",
    "    )\n",
    "\n",
    "    bot_reply = response.choices[0].message.content\n",
    "    print(f\"\\nIA: {bot_reply}\")\n",
    "    history.append({\"role\": \"assistant\", \"content\": bot_reply})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
